{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Kevin Pham\n",
        "\n",
        "\n",
        "Research Question\n",
        "  \"Does a home win in an NBA or NFL game lead to a measurable difference in daily restaurant and bar spending in major U.S. Cities?"
      ],
      "metadata": {
        "id": "uRKIiIuZyBvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Similar Research**\n",
        "\n",
        "\n",
        "Selling the Game: Estimating the Economic Impact of Professional Sports through Taxable Sales\n",
        "  \n",
        "  By Robert A. Baade, Robert Baumann and Victor A. Matheson\n",
        "\n",
        "Findings:\n",
        "  - New Facilities and franchises don't reliably boost retail sales\n",
        "  - Mega-Events have no consistent positive effet\n",
        "  - Strikes and lockouts (interuptions in a season) have minimal effect\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Estimating Local Welfare Generated by an NFL Team under Credible Threat of Relocation\n",
        "\n",
        "  By Aju J. Fenn and John R. Crooker\n",
        "\n",
        "Findings:\n",
        "  - Credible Relocation Threat is credible\n",
        "      - Peoples willingness to pay doesn't change without perception that franchise might actually leave\n"
      ],
      "metadata": {
        "id": "YnkRu17Ixuob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sources of Data\n",
        "  \n",
        "  Opportunity insights Economic tracker\n",
        "\n",
        "   - Affinity Federal Credit Union Credit Card Spending Data\n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "  NBA API and Pro Football Reference for Sports Data"
      ],
      "metadata": {
        "id": "Ww4ld2ca01Lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nba_api\n",
        "!pip install beautifulsoup4\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from nba_api.stats.endpoints import leaguegamefinder\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.decomposition import PCA\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "th-sWTCgFhjh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c708b6dd-0f52-4fcd-d2d7-d9f457228a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nba_api in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from nba_api) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from nba_api) (2.2.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from nba_api) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->nba_api) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->nba_api) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->nba_api) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1.0->nba_api) (1.17.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cleaning Economic Data\n",
        "Spending_df = pd.read_csv('/content/Affinity - City - Daily.csv')\n",
        "\n",
        "#Define desired columns and city IDs\n",
        "spending_cols =['spend_acf','spend_inperson','spend_all']\n",
        "display_cols = ['cityid', 'year', 'month', 'day']\n",
        "city_ids = [1, 2, 3, 7, 13, 14, 17, 18, 21, 28, 29, 36, 38, 44]\n",
        "\n",
        "#Create Spending df\n",
        "Spending_df[spending_cols] = Spending_df[spending_cols].apply(pd.to_numeric, errors='coerce')\n",
        "Spending_df = Spending_df.dropna(subset = spending_cols)\n",
        "Spending_df = Spending_df[Spending_df['cityid'].isin(city_ids)]\n",
        "Spending_df = Spending_df[display_cols + spending_cols]\n",
        "\n",
        "#Mapping City IDs to names\n",
        "ID_to_name = {\n",
        "    1: 'Los Angeles', 2: 'New York City', 3: 'Chicago', 7: \"Dallas\", 13: \"Detriot\", 14: 'Philadelphia', 17: 'Charlotte',\n",
        "    18: 'Indianapolis', 21: 'San Francisco', 28: 'Denver', 29: 'Washington DC', 36: 'Atlanta', 38: 'Miami', 44: 'New Orleans'}\n",
        "\n",
        "#Adding city name col\n",
        "Spending_df['city_name'] = Spending_df['cityid'].map(ID_to_name)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hXRPthXDF3HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDNj0zEjpsWt",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#Get Sports Data\n",
        "\n",
        "#Teams needed and mapping cities\n",
        "nba_teams = [\n",
        "    'Lakers','Clippers','Knicks','Bulls','Mavericks','Pistons','76ers','Hornets'\n",
        "    ,'Pacers','Warriors','Nuggets','Wizards','Hawks','Heat','Pelicans']\n",
        "\n",
        "nfl_teams = [\n",
        "    'Los Angeles Rams', 'Los Angeles Chargers', 'New York Giants', 'Chicago Bears', 'Dallas Cowboys',\n",
        "    'Detroit Lions', 'Philadelphia Eagles', 'Carolina Panthers', 'Indianapolis Colts',\n",
        "    'San Francisco 49ers', 'Denver Broncos', 'Washington Commanders',\n",
        "    'Atlanta Falcons', 'Miami Dolphins', 'New Orleans Saints']\n",
        "\n",
        "nba_cities = [\n",
        "    'Los Angeles','Los Angeles','New York City','Chicago','Dallas','Detroit',\n",
        "    'Philadelphia','Charlotte','Indianapolis','San Francisco','Denver',\n",
        "    'Washington DC','Atlanta','Miami','New Orleans']\n",
        "\n",
        "nba_mapping = dict(zip(nba_teams, nba_cities))\n",
        "\n",
        "nfl_cities = [\n",
        "    'Los Angeles','Los Angeles','New York City','Chicago','Dallas','Detroit',\n",
        "    'Philadelphia','Charlotte','Indianapolis','San Francisco','Denver',\n",
        "    'Washington DC','Atlanta','Miami','New Orleans']\n",
        "nfl_mapping = dict(zip(nfl_teams, nfl_cities))\n",
        "\n",
        "teams_to_city = {}\n",
        "teams_to_city.update(nba_mapping)\n",
        "teams_to_city.update(nfl_mapping)\n",
        "\n",
        "\n",
        "#Scrape NFL data\n",
        "def nfl_data(start_year, end_year):\n",
        "    game_list = []\n",
        "    #Loop for years\n",
        "    for year in range(start_year, end_year + 1):\n",
        "        url = f'https://www.pro-football-reference.com/years/{year}/games.htm'\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        table = soup.find('table', {'id': 'games'})\n",
        "\n",
        "        #Read table into a dataframe\n",
        "        df = pd.read_html(str(table))[0]\n",
        "\n",
        "        #Filter Columns and clean\n",
        "        df = df[['Date', 'Winner/tie', 'Loser/tie', 'Unnamed: 7']]\n",
        "        df['Year'] = year\n",
        "        #Fix date format\n",
        "        df['Date'] = pd.to_datetime(df['Date'].str.replace(r\".*,\\s*\",\"\", regex = True) + ' ' + df['Year'].astype(str), errors = 'coerce' )\n",
        "        df = df[df['Date'].notna()]\n",
        "\n",
        "        #Map Teams to cities\n",
        "        df['City'] = df['Winner/tie'].map(teams_to_city).fillna(df['Loser/tie'].map(teams_to_city))\n",
        "        df['Sport'] = 'NFL'\n",
        "\n",
        "        #Determine home or away game\n",
        "        df['home_game'] = df['Unnamed: 7'].apply(lambda x: 0 if x == '@' else 1)\n",
        "\n",
        "        #Determine win/loss\n",
        "        df['win'] = df['Winner/tie'].apply(lambda x: 1 if x in nfl_teams else 0)\n",
        "\n",
        "        game_list.append(df)\n",
        "\n",
        "    nfl_df = pd.concat(game_list, ignore_index=True)\n",
        "    return nfl_df\n",
        "\n",
        "#Function for NBA data\n",
        "def nba_data(start_year, end_year):\n",
        "    game_list = []\n",
        "    #Loop for years\n",
        "    for year in range(start_year, end_year + 1):\n",
        "        season = str(year) + '-' + str(year + 1)[-2:]\n",
        "        gamefinder = leaguegamefinder.LeagueGameFinder(season_nullable=season)\n",
        "        #Get Schedule\n",
        "        games = gamefinder.get_data_frames()[0]\n",
        "\n",
        "        #Filter need NBA teams\n",
        "        games = games[games['TEAM_NAME'].isin(nba_teams)]\n",
        "        #Filter Home Games\n",
        "        games['home_game'] = games['MATCHUP'].apply(lambda x: 1 if 'vs.' not in x else 0)\n",
        "        #Filter Wins\n",
        "        games['win'] = games['WL'].apply(lambda x: 1 if x == 'W' else 0)\n",
        "        games['city_name'] = games['TEAM_NAME'].map(teams_to_city)\n",
        "        games['sport'] = 'NBA'\n",
        "        game_list.append(games[['TEAM_NAME','city_name','GAME_DATE','home_game','win','sport']])\n",
        "    nba_df = pd.concat(game_list, ignore_index=True)\n",
        "    nba_df.rename(columns={'TEAM_NAME': 'Team', 'GAME_DATE': 'Date'}, inplace=True)\n",
        "    return nba_df\n",
        "\n",
        "#get data for both NFL and NBA\n",
        "nfl_games = nfl_data(2020, 2024)\n",
        "nba_games = nba_data(2020, 2024)\n",
        "\n",
        "#Keep relevant nfl cities\n",
        "nfl_games = nfl_games[nfl_games['City'].notna()]\n",
        "\n",
        "#Normalize column names\n",
        "nfl_games = (nfl_games.rename(columns={'Winner/tie':'Team','City': 'city_name'})[['Date','Team','city_name','home_game','win','Sport']])\n",
        "nba_games = (nba_games.rename(columns={'TEAM_NAME':'Team','city_name': 'city_name'})[['Date','Team','city_name','home_game','win','sport']])\n",
        "\n",
        "#Remove time from output\n",
        "nfl_games['Date'] = nfl_games['Date'].dt.floor('d')\n",
        "nba_games['Date'] = pd.to_datetime(nba_games['Date']).dt.floor('d')\n",
        "\n",
        "\n",
        "#Combine\n",
        "sports_games = pd.concat([nfl_games, nba_games], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Merging Spending and Sports data\n",
        "\n",
        "#Formatting Spending DF\n",
        "Spending_df['Date'] = pd.to_datetime(Spending_df[['year','month','day']]).dt.floor('d')\n",
        "Spending_df = Spending_df.rename(columns = {'city':'city_name'})\n",
        "\n",
        "#Merging\n",
        "merged_df = pd.merge( Spending_df,sports_games, on = ['city_name','Date'], how = 'left')\n",
        "merged_df[['home_game','win']] = merged_df[['home_game','win']].fillna(0).astype(int)\n",
        "merged_df['dow'] = merged_df['Date'].dt.day_name() # Day of Week\n",
        "merged_df['month'] = merged_df['Date'].dt.month # Month\n",
        "\n",
        "X = merged_df[['home_game','win']].values\n",
        "y = merged_df['spend_acf'].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_std = scaler.fit_transform(X)\n",
        "\n",
        "#Baseline OLS\n",
        "X0 = sm.add_constant(merged_df['home_game'])\n",
        "print('\\nBaseline OLS:')\n",
        "print(sm.OLS(merged_df['spend_acf'], X0).fit().summary())\n",
        "\n",
        "#Create Dummies\n",
        "dow_dummy = pd.get_dummies(merged_df['dow'], prefix = 'dow', drop_first = True)\n",
        "month_dummy = pd.get_dummies(merged_df['month'], prefix = 'month', drop_first = True)\n",
        "city_dummy = pd.get_dummies(merged_df['city_name'], prefix = 'city', drop_first = True)\n",
        "\n",
        "Fixed_effects = pd.concat([merged_df[['home_game','win']],dow_dummy,month_dummy,city_dummy], axis = 1)\n",
        "Fixed_effects_const = sm.add_constant(Fixed_effects).astype(float)\n",
        "\n",
        "#Cluster OLS w/ City dummies\n",
        "y = merged_df['spend_acf'].values\n",
        "\n",
        "ols_clustered = sm.OLS(y, Fixed_effects_const).fit(cov_type = 'cluster',cov_kwds={'groups': merged_df['city_name']})\n",
        "print('\\nClustered OLS with DOW, Month, and City dummies:')\n",
        "print(ols_clustered.summary())\n",
        "\n",
        "#PCA\n",
        "#Create df of dummies\n",
        "dummies = pd.concat([dow_dummy, month_dummy, city_dummy], axis = 1)\n",
        "#Standardze dummies\n",
        "dummy_std = StandardScaler().fit_transform(dummies)\n",
        "\n",
        "pca = PCA(n_components = 10).fit(dummy_std)\n",
        "pca_result = pca.transform(dummy_std)\n",
        "#Combine home game, wins and components\n",
        "pca_df = np.column_stack ([merged_df[['home_game','win']].values,pca_result])\n",
        "pca_df = sm.add_constant(pca_df)\n",
        "\n",
        "model = sm.OLS(y, pca_df).fit()\n",
        "print('\\nPCA Results:')\n",
        "print(model.summary())\n",
        "\n",
        "#Alphas for regression\n",
        "alphas_reg = np.logspace(-6,2,50)\n",
        "\n",
        "#Ridge\n",
        "ridge_std = StandardScaler().fit_transform(Fixed_effects)\n",
        "ridge = RidgeCV(alphas = alphas_reg, cv = 5).fit(ridge_std, y)\n",
        "print(\"\\nRidge alpha:\", ridge.alpha_)\n",
        "\n",
        "\n",
        "#Elastic Net\n",
        "elastic = ElasticNetCV(alphas = alphas_reg, l1_ratio=[0.1,0.5,0.9], cv = 5,max_iter = 10000).fit(X_std, y)\n",
        "print(\"\\nElasticNet alpha:\", elastic.alpha_)\n",
        "\n",
        "#LASSO\n",
        "lasso_std = StandardScaler().fit_transform(Fixed_effects.values)\n",
        "lasso = LassoCV(alphas = alphas_reg, cv = 5, max_iter = 10000).fit(lasso_std, y)\n",
        "print(\"\\nNonzero LASSO coefs:\", [f for f, c in zip(Fixed_effects.columns, lasso.coef_) if c != 0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EFEUvNqC-M6",
        "outputId": "44a4c8ad-5a91-400e-ec8e-4af927637d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Baseline OLS:\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:              spend_acf   R-squared:                       0.001\n",
            "Model:                            OLS   Adj. R-squared:                  0.001\n",
            "Method:                 Least Squares   F-statistic:                     8.056\n",
            "Date:                Sun, 11 May 2025   Prob (F-statistic):            0.00454\n",
            "Time:                        00:55:06   Log-Likelihood:                 268.73\n",
            "No. Observations:               10813   AIC:                            -533.5\n",
            "Df Residuals:                   10811   BIC:                            -518.9\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -0.1332      0.002    -57.245      0.000      -0.138      -0.129\n",
            "home_game      0.0302      0.011      2.838      0.005       0.009       0.051\n",
            "==============================================================================\n",
            "Omnibus:                      606.335   Durbin-Watson:                   0.377\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              797.160\n",
            "Skew:                          -0.535   Prob(JB):                    7.92e-174\n",
            "Kurtosis:                       3.790   Cond. No.                         4.70\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "\n",
            "Clustered OLS with DOW, Month, and City dummies:\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.172\n",
            "Model:                            OLS   Adj. R-squared:                  0.170\n",
            "Method:                 Least Squares   F-statistic:                     133.3\n",
            "Date:                Sun, 11 May 2025   Prob (F-statistic):           2.81e-09\n",
            "Time:                        00:55:06   Log-Likelihood:                 1284.2\n",
            "No. Observations:               10813   AIC:                            -2508.\n",
            "Df Residuals:                   10783   BIC:                            -2290.\n",
            "Df Model:                          29                                         \n",
            "Covariance Type:              cluster                                         \n",
            "======================================================================================\n",
            "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------------\n",
            "const                 -0.0588      0.004    -15.605      0.000      -0.066      -0.051\n",
            "home_game             -0.0146      0.009     -1.636      0.102      -0.032       0.003\n",
            "win                    0.0024      0.016      0.153      0.878      -0.029       0.033\n",
            "dow_Monday            -0.0009      0.000     -3.660      0.000      -0.001      -0.000\n",
            "dow_Saturday          -0.0014      0.000     -3.347      0.001      -0.002      -0.001\n",
            "dow_Sunday             0.0857      0.005     18.946      0.000       0.077       0.095\n",
            "dow_Thursday       -5.141e-05      0.000     -0.129      0.897      -0.001       0.001\n",
            "dow_Tuesday           -0.0001      0.000     -0.310      0.756      -0.001       0.001\n",
            "dow_Wednesday          0.0003      0.000      0.859      0.390      -0.000       0.001\n",
            "month_2                0.0568      0.008      6.736      0.000       0.040       0.073\n",
            "month_3               -0.0280      0.006     -4.783      0.000      -0.039      -0.017\n",
            "month_4               -0.1009      0.007    -14.553      0.000      -0.115      -0.087\n",
            "month_5               -0.0778      0.006    -12.763      0.000      -0.090      -0.066\n",
            "month_6               -0.0786      0.008     -9.569      0.000      -0.095      -0.062\n",
            "month_7               -0.0781      0.011     -6.905      0.000      -0.100      -0.056\n",
            "month_8               -0.0604      0.009     -6.649      0.000      -0.078      -0.043\n",
            "month_9               -0.0170      0.025     -0.677      0.498      -0.066       0.032\n",
            "month_10              -0.0211      0.007     -3.169      0.002      -0.034      -0.008\n",
            "month_11              -0.0263      0.006     -4.363      0.000      -0.038      -0.014\n",
            "month_12              -0.0713      0.006    -12.665      0.000      -0.082      -0.060\n",
            "city_Charlotte         0.0010      0.000      8.475      0.000       0.001       0.001\n",
            "city_Chicago          -0.0510   8.08e-05   -630.934      0.000      -0.051      -0.051\n",
            "city_Dallas           -0.0002   9.96e-05     -1.870      0.061      -0.000    8.93e-06\n",
            "city_Denver           -0.0449   8.62e-05   -521.405      0.000      -0.045      -0.045\n",
            "city_Detriot           0.0637      0.000    242.968      0.000       0.063       0.064\n",
            "city_Los Angeles      -0.1288      0.000   -377.649      0.000      -0.129      -0.128\n",
            "city_Miami             0.0161      0.000    117.856      0.000       0.016       0.016\n",
            "city_New Orleans      -0.0708   9.79e-05   -723.232      0.000      -0.071      -0.071\n",
            "city_New York City    -0.1042   3.58e-05  -2906.442      0.000      -0.104      -0.104\n",
            "city_San Francisco    -0.2385      0.000  -1484.460      0.000      -0.239      -0.238\n",
            "==============================================================================\n",
            "Omnibus:                      613.628   Durbin-Watson:                   0.216\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1173.037\n",
            "Skew:                          -0.417   Prob(JB):                    1.90e-255\n",
            "Kurtosis:                       4.381   Cond. No.                         14.0\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors are robust to cluster correlation (cluster)\n",
            "\n",
            "PCA Results:\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.049\n",
            "Model:                            OLS   Adj. R-squared:                  0.048\n",
            "Method:                 Least Squares   F-statistic:                     46.86\n",
            "Date:                Sun, 11 May 2025   Prob (F-statistic):          1.08e-109\n",
            "Time:                        00:55:06   Log-Likelihood:                 539.11\n",
            "No. Observations:               10813   AIC:                            -1052.\n",
            "Df Residuals:                   10800   BIC:                            -957.5\n",
            "Df Model:                          12                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -0.1314      0.002    -57.689      0.000      -0.136      -0.127\n",
            "x1            -0.0017      0.017     -0.098      0.922      -0.035       0.032\n",
            "x2            -0.0074      0.021     -0.354      0.723      -0.048       0.033\n",
            "x3             0.0269      0.002     12.904      0.000       0.023       0.031\n",
            "x4             0.0040      0.002      1.956      0.051   -9.22e-06       0.008\n",
            "x5            -0.0024      0.002     -1.185      0.236      -0.006       0.002\n",
            "x6            -0.0044      0.002     -2.105      0.035      -0.008      -0.000\n",
            "x7             0.0005      0.002      0.221      0.825      -0.004       0.005\n",
            "x8            -0.0256      0.002    -12.152      0.000      -0.030      -0.021\n",
            "x9            -0.0132      0.002     -6.271      0.000      -0.017      -0.009\n",
            "x10            0.0100      0.002      4.734      0.000       0.006       0.014\n",
            "x11           -0.0257      0.002    -12.108      0.000      -0.030      -0.022\n",
            "x12           -0.0066      0.002     -3.138      0.002      -0.011      -0.002\n",
            "==============================================================================\n",
            "Omnibus:                      339.440   Durbin-Watson:                   0.385\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              447.968\n",
            "Skew:                          -0.354   Prob(JB):                     5.31e-98\n",
            "Kurtosis:                       3.701   Cond. No.                         12.9\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "\n",
            "Ridge alpha: 100.0\n",
            "\n",
            "ElasticNet alpha: 100.0\n",
            "\n",
            "Nonzero LASSO coefs: ['city_San Francisco']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Takeaways\n",
        " - Baseline OLS shows that home games create a boost in spending\n",
        "    - R^2 value shows that this model isn't significant and home games don't really explain much\n",
        " - RidgeCV and ElasticNetCV show large penalities, shrinking all sports related factors significantly\n",
        "\n",
        " - PCR shows that home games or wins don't have a great effect when other facotrs are taken into consideration\n",
        "\n",
        " - Home games or wins and losses dont have much of an effect on restaurant spending overall."
      ],
      "metadata": {
        "id": "PaNZpk9P96ez"
      }
    }
  ]
}